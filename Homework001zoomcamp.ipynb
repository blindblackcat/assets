{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNU+0wS2wKqN/LC3q7oUi3b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blindblackcat/assets/blob/main/Homework001zoomcamp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaHqbEGIb3LM"
      },
      "outputs": [],
      "source": [
        "!pip install yfinance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTS\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#Fin Data Sources\n",
        "import yfinance as yf\n",
        "import pandas_datareader as pdr\n",
        "\n",
        "#Data viz\n",
        "import plotly.graph_objs as go\n",
        "import plotly.express as px\n",
        "\n",
        "import time\n",
        "from datetime import datetime\n",
        "from datetime import date"
      ],
      "metadata": {
        "id": "qXcd3wN3cz1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SP500ListLink=\"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
        "SP500=pd.read_html(SP500ListLink)\n"
      ],
      "metadata": {
        "id": "ETa-kk2idiHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SP500Stocks = SP500[0]\n",
        "SP500Changes = SP500[1]"
      ],
      "metadata": {
        "id": "e-be8GcOd6mA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SP500Stocks"
      ],
      "metadata": {
        "id": "Jsxo39pWf7QJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SP500Changes"
      ],
      "metadata": {
        "id": "Jy-lhUyVf92d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SP500Stocks[\"Date added\"]=pd.to_datetime(SP500Stocks[\"Date added\"])"
      ],
      "metadata": {
        "id": "OHKZsfoYeJP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pt=pd.pivot_table(SP500Stocks,values=\"Security\",index=\"Date added\",aggfunc=\"count\")"
      ],
      "metadata": {
        "id": "vqMVckW1hpKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearly=pt.resample(\"YE\").sum().sort_values(by=\"Security\",ascending=False)"
      ],
      "metadata": {
        "id": "tyWuhCWQjAdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from matplotlib import pyplot as plt\n",
        "yearly.plot(kind='bar', figsize=(20, 10), title='Yearly Changes')\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "90OtAnZJlH7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "pt.plot(kind='line', figsize=(20, 10), title='Yearly Changes')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-EgrwHrdjWce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Top3 = yearly.nlargest(3,\"Security\")\n",
        "Top3\n"
      ],
      "metadata": {
        "id": "d89Vpqvvl9O3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SP500Changes[('Date', 'Date')] = pd.to_datetime(SP500Changes[('Date', 'Date')])\n",
        "mask = SP500Changes[('Date', 'Date')].dt.year.isin([2016, 2017])\n",
        "filtered_df = SP500Changes.loc[mask]\n"
      ],
      "metadata": {
        "id": "aGLVLuTOpA3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df\n",
        "\n"
      ],
      "metadata": {
        "id": "XmvXVeUxp-FN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bertopic sentence-transformers\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nRDTt6BPqe9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies if not done\n",
        "# !pip install bertopic sentence-transformers umap-learn plotly\n",
        "\n",
        "from bertopic import BERTopic\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import umap.umap_ as umap\n",
        "import pandas as pd\n",
        "import plotly.io as pio\n",
        "\n",
        "# OPTIONAL: Display Plotly in browser\n",
        "pio.renderers.default = \"browser\"\n",
        "\n",
        "# Load and clean your data\n",
        "texts = SP500Changes[('Reason', 'Reason')].dropna().astype(str).tolist()\n",
        "\n",
        "# UMAP: better tuned for short text\n",
        "umap_model = umap.UMAP(\n",
        "    n_neighbors=3,\n",
        "    n_components=2,\n",
        "    min_dist=0.1,\n",
        "    metric='cosine',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# SentenceTransformer: good for short texts\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Initialize BERTopic with embedding + umap\n",
        "topic_model = BERTopic(\n",
        "    embedding_model=embedding_model,\n",
        "    umap_model=umap_model,\n",
        "    language=\"english\",\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Fit model\n",
        "topics, probs = topic_model.fit_transform(texts)\n",
        "\n",
        "# Get topic info\n",
        "topic_info = topic_model.get_topic_info()\n",
        "print(topic_info.head())\n",
        "\n",
        "# Visualize\n",
        "fig = topic_model.visualize_topics()\n",
        "fig = topic_model.visualize_topics()\n",
        "fig.write_html(\"topics_visualization.html\")\n",
        "from google.colab import files\n",
        "files.download(\"topics_visualization.html\")\n"
      ],
      "metadata": {
        "id": "_4FH8h3SuQrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer to question 1:**\n",
        "\n",
        "The Year with the most additions was 2017\n",
        "\n",
        "D1:\n",
        "* Low interest rates made it easy and cheap for companies and private equity firms to finance mergers and acquisitions.\n",
        "\n",
        "* Private equity activity surged, leading to many public companies\n",
        "being acquired and taken private, requiring replacements in the index.\n",
        "\n",
        "* Tech and pharma companies had large cash reserves and used them to:\n",
        "\n",
        "\n",
        "\n",
        "1. Acquire smaller companies\n",
        "2. Spin off divisions\n",
        "3. Restructure operations\n",
        "\n",
        "*  Spin off divisions,Restructure operations,Anticipation of U.S. tax reform under the Trump administration led to a rush of corporate actions before policy changes took effect.\n",
        "\n",
        "D2\n",
        "\n",
        "* Market capitalization shifts triggered index adjustments, as companies grew or shrank relative to others.\n",
        "\n",
        "* Structural changes to the S&P, like the creation of the Real Estate sector in 2016.\n",
        "\n",
        "* These years were marked by unusually high corporate activity, especially in tech, pharma, and private equity  all contributing to the pike."
      ],
      "metadata": {
        "id": "odYfOdO-1sg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SP500ComponentStocks.columns"
      ],
      "metadata": {
        "id": "rnzmN1jG5BH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SP500ComponentStocks[\"TimeInIndex\"]=pd.Timestamp.today()-SP500ComponentStocks[\"Date added\"]\n",
        "SP500ComponentStocks[\"TimeInIndex\"]=SP500ComponentStocks[\"TimeInIndex\"].dt.days/365 #Not 252 days since is datetime year, not financial."
      ],
      "metadata": {
        "id": "aaM51Cu96jVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y20securities=SP500ComponentStocks[SP500ComponentStocks[\"TimeInIndex\"]>20].sort_values(by=\"TimeInIndex\",ascending=0).reset_index(drop=1)"
      ],
      "metadata": {
        "id": "84GSvrgi8eyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y20securities"
      ],
      "metadata": {
        "id": "hZEAasd_-VrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clean The data:\n",
        "\n",
        "1. understand why Date added before foundation date in some securities."
      ],
      "metadata": {
        "id": "M7uYVf21JWcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SP500ComponentStocks[\"Founded_clean\"] = SP500ComponentStocks[\"Founded\"].astype(str).str.extract(r'(\\d{4})')\n",
        "\n",
        "SP500ComponentStocks[\"error\"] = SP500ComponentStocks.apply(\n",
        "    lambda row: (\n",
        "        f\"Error: added in {pd.to_datetime(row['Date added'], errors='coerce').year} \"\n",
        "        f\"but founded in {int(row['Founded_clean'])}\"\n",
        "    )\n",
        "    if pd.notna(row[\"Date added\"])\n",
        "       and pd.notna(row[\"Founded_clean\"])\n",
        "       and pd.to_datetime(row[\"Date added\"], errors='coerce').year < int(row[\"Founded_clean\"])\n",
        "    else None,\n",
        "    axis=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "RMT33tPbKA2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SP500ComponentStocks"
      ],
      "metadata": {
        "id": "gymLv_4NLctZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SP500ComponentStocks[SP500ComponentStocks[\"error\"].notna()][[\"Security\", \"error\"]].reset_index(drop=1)\n"
      ],
      "metadata": {
        "id": "Cx35RotSJlSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "error_list = pd.DataFrame({\n",
        "    \"Security\": [\n",
        "        \"AbbVie\", \"Altria\", \"Bank of America\", \"Bristol Myers Squibb\", \"Cigna\", \"Citigroup\", \"ConocoPhillips\",\n",
        "        \"Coterra\", \"CSX Corporation\", \"CVS Health\", \"DTE Energy\", \"Elevance Health\", \"Exelon\", \"ExxonMobil\",\n",
        "        \"JPMorgan Chase\", \"L3Harris\", \"Lockheed Martin\", \"Molson Coors Beverage Company\", \"NextEra Energy\",\n",
        "        \"Northrop Grumman\", \"Paramount Global\", \"Simon Property Group\", \"Tapestry, Inc.\", \"Thermo Fisher Scientific\",\n",
        "        \"TJX Companies\", \"Walgreens Boots Alliance\"\n",
        "    ],\n",
        "    \"error\": [\n",
        "        \"Error: added in 2012 but founded in 2013\", \"Error: added in 1957 but founded in 1985\",\n",
        "        \"Error: added in 1976 but founded in 1998\", \"Error: added in 1957 but founded in 1989\",\n",
        "        \"Error: added in 1976 but founded in 1982\", \"Error: added in 1988 but founded in 1998\",\n",
        "        \"Error: added in 1957 but founded in 2002\", \"Error: added in 2008 but founded in 2021\",\n",
        "        \"Error: added in 1957 but founded in 1980\", \"Error: added in 1957 but founded in 1996\",\n",
        "        \"Error: added in 1957 but founded in 1995\", \"Error: added in 2002 but founded in 2014\",\n",
        "        \"Error: added in 1957 but founded in 2000\", \"Error: added in 1957 but founded in 1999\",\n",
        "        \"Error: added in 1975 but founded in 2000\", \"Error: added in 2008 but founded in 2019\",\n",
        "        \"Error: added in 1957 but founded in 1995\", \"Error: added in 1976 but founded in 2005\",\n",
        "        \"Error: added in 1976 but founded in 1984\", \"Error: added in 1957 but founded in 1994\",\n",
        "        \"Error: added in 1994 but founded in 2019\", \"Error: added in 2002 but founded in 2003\",\n",
        "        \"Error: added in 2004 but founded in 2017\", \"Error: added in 2004 but founded in 2006\",\n",
        "        \"Error: added in 1985 but founded in 1987\", \"Error: added in 1979 but founded in 2014\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "# The corrected founded and S&P 500 added dates for these companies\n",
        "corrections = pd.DataFrame({\n",
        "    \"Security\": [\n",
        "        \"AbbVie\", \"Altria\", \"Bank of America\", \"Bristol Myers Squibb\", \"Cigna\", \"Citigroup\", \"ConocoPhillips\",\n",
        "        \"Coterra\", \"CSX Corporation\", \"CVS Health\", \"DTE Energy\", \"Elevance Health\", \"Exelon\", \"ExxonMobil\",\n",
        "        \"JPMorgan Chase\", \"L3Harris\", \"Lockheed Martin\", \"Molson Coors Beverage Company\", \"NextEra Energy\",\n",
        "        \"Northrop Grumman\", \"Paramount Global\", \"Simon Property Group\", \"Tapestry, Inc.\", \"Thermo Fisher Scientific\",\n",
        "        \"TJX Companies\", \"Walgreens Boots Alliance\"\n",
        "    ],\n",
        "    \"Correct Founded\": [\n",
        "        2012, 1985, 1998, 1989, 1982, 1998, 2002, 2021, 1980, 1963, 1995, 2014, 2000, 1999,\n",
        "        2000, 2019, 1995, 2005, 1984, 1994, 2019, 2003, 2017, 2006, 1987, 2014\n",
        "    ],\n",
        "    \"S&P 500 Added\": [\n",
        "        2012, 1957, 1976, 1957, 1976, 1988, 1957, 2008, 1957, 1997, 1957, 2002, 1957, 1957,\n",
        "        1975, 2008, 1957, 1976, 1976, 1957, 1994, 2002, 2004, 2004, 1985, 1979\n",
        "    ]\n",
        "})\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AAmKIGuqOtVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Crear diccionarios de corrección\n",
        "founded_dict = dict(zip(corrections['Security'], corrections['Correct Founded']))\n",
        "added_dict = dict(zip(corrections['Security'], corrections['S&P 500 Added']))\n",
        "\n",
        "\n",
        "SP500ComponentStocks['Founded'] = SP500ComponentStocks.apply(\n",
        "    lambda row: founded_dict[row['Security']] if row['Security'] in founded_dict else row['Founded'],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "\n",
        "SP500ComponentStocks['Date added'] = SP500ComponentStocks.apply(\n",
        "    lambda row: added_dict[row['Security']] if row['Security'] in added_dict else row['Date added'],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "SP500ComponentStocks['Year Added'] = pd.to_datetime(SP500ComponentStocks['Date added'], errors='coerce').dt.year\n",
        "\n"
      ],
      "metadata": {
        "id": "r-UROTyLT1KQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "current_year = datetime.now().year\n",
        "SP500ComponentStocks[\"YearsInIndex\"] = current_year - SP500ComponentStocks[\"Year Added\"]\n",
        "\n",
        "over_20_years_count = SP500ComponentStocks[SP500ComponentStocks[\"YearsInIndex\"] >= 20][\"Security\"].nunique()\n",
        "\n",
        "print(\"Número de compañías con más de 20 años en el S&P 500:\", over_20_years_count)\n"
      ],
      "metadata": {
        "id": "PJPHpmcSXEp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "229 companies have been in the index whether under their first foundation name or other."
      ],
      "metadata": {
        "id": "bhvVP_zBXTSq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UK12bGQYXr_d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}